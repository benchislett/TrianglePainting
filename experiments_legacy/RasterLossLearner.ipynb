{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 200\n",
    "image_height = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load target image \"lisa.png\"\n",
    "target_image = Image.open(\"../build/lisa.png\")\n",
    "assert target_image.size == (image_width, image_height)\n",
    "target_image_np = (np.asarray(target_image).astype(np.float32) / 255.0)[:, :, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_color(col):\n",
    "    return tuple(map(lambda i: max(0, min(255, int(i * 255.99))), col))\n",
    "\n",
    "def rasterize_polygon(background, colours, shapes):\n",
    "    image = Image.new(\"RGBA\", (image_width, image_height))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    draw.polygon([(0, 0), (0, image_height), (image_width, image_height), (image_width, 0)],\n",
    "                fill=unpack_color(background))\n",
    "\n",
    "    for colour, shape in zip(colours, shapes):\n",
    "        new_triangle = Image.new(\"RGBA\", (image_width, image_height))\n",
    "        tdraw = ImageDraw.Draw(new_triangle)\n",
    "        tdraw.polygon([(x*image_width, y*image_height) for x, y in shape], fill=unpack_color(colour))\n",
    "\n",
    "        image = Image.alpha_composite(image, new_triangle)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def generate_random_batch(batch_size, num_vertices, num_shapes):\n",
    "    \"\"\"Generate a batch of tensors representing collections of shapes, with each tensor having shapes with an RGBA colour and vertex positions, each on [0, 1]. Each tensor also includes a prepended RGB colour for the background.\"\"\"\n",
    "    inputs, targets = [], []\n",
    "    for _ in range(batch_size):\n",
    "        background = np.random.rand(3)\n",
    "        colours = np.random.rand(num_shapes, 4)\n",
    "        vertices = np.random.rand(num_shapes, num_vertices, 2)\n",
    "\n",
    "        rasterized_image = rasterize_polygon(background, colours, vertices)\n",
    "        rasterized_image_np = (np.asarray(rasterized_image).astype(np.float32) / 255.0)[:, :, 0:3]\n",
    "\n",
    "        # compute the mse loss between the rasterized image and the target image\n",
    "        loss = np.mean((rasterized_image_np - target_image_np) ** 2)\n",
    "\n",
    "        inputs.append(np.concatenate([background, colours.flatten(), vertices.flatten()]))\n",
    "        targets.append(loss)\n",
    "    return torch.tensor(np.array(inputs), dtype=torch.float32), torch.tensor(np.array(targets), dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPolygonDataset(IterableDataset):\n",
    "    def __init__(self, num_batches, batch_size, num_vertices, num_shapes):\n",
    "        self.num_batches = num_batches\n",
    "        self.batch_size = batch_size\n",
    "        self.num_vertices = num_vertices\n",
    "        self.num_shapes = num_shapes\n",
    "\n",
    "    def __iter__(self):\n",
    "        for _ in range(self.num_batches):\n",
    "            yield generate_random_batch(self.batch_size, self.num_vertices, self.num_shapes)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_batches = 64\n",
    "dataset = RandomPolygonDataset(num_batches, batch_size, 3, 50)\n",
    "data_loader = DataLoader(dataset, batch_size=None)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nn.Sequential(\n",
    "#     nn.Linear(3 + 50 * (3 * 2 + 4), 512), # 3 for RGB background + 50 shapes with 3 vertices each, and 4 for RGBA colour\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(512, 512),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(512, 512),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(512, 512),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(512, 256),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(256, 32),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(32, 1)\n",
    "# )\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(256, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.hidden(x)\n",
    "        return self.output(x)\n",
    "\n",
    "def init_weights(layer):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        init.kaiming_uniform_(layer.weight, nonlinearity='relu')\n",
    "        if layer.bias is not None:  # Bias initialization (optional but often useful)\n",
    "            init.zeros_(layer.bias)\n",
    "\n",
    "model = MLP(3 + 50 * (3 * 2 + 4))\n",
    "model = model.to(device)\n",
    "model.apply(init_weights) # weight initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1000):\n",
    "    loss_aggregate = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(inputs).squeeze()\n",
    "        loss = loss_fn(predictions, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_aggregate += loss.item()\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}, Mean Loss: {loss_aggregate / num_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time the generation of a batch of size 1000\n",
    "from timeit import timeit\n",
    "print(timeit(lambda: generate_random_batch(100, 3, 50), number=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, outputs = generate_random_batch(1000, 3, 50)\n",
    "inputs, outputs = inputs.to(device), outputs.to(device)\n",
    "model(inputs).squeeze(), outputs\n",
    "\n",
    "outputs_np, predictions_np = outputs.cpu().detach().numpy(), model(inputs).squeeze().cpu().detach().numpy()\n",
    "\n",
    "# plot model predictions against outputs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(outputs_np, predictions_np)\n",
    "\n",
    "# draw a correlation line\n",
    "z = np.polyfit(outputs_np, predictions_np, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(outputs_np, p(outputs_np), \"r--\")\n",
    "\n",
    "# print the correlation coefficient\n",
    "print(np.corrcoef(outputs_np, predictions_np)[0, 1])\n",
    "\n",
    "# print the line equation\n",
    "print(f\"y = {z[0]}x + {z[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, outputs = generate_random_batch(1, 3, 50)\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "# use gradient descent to optimize the input such that it minimizes the model's output\n",
    "inputs.requires_grad = True\n",
    "optimizer = optim.Adam([inputs], lr=1e-3)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    loss = model(inputs).squeeze()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if loss.item() < 1e-4:\n",
    "        break\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasterize_polygon(inputs[0, 0:3].cpu().detach().numpy(), inputs[0, 3:3+50*4].reshape(50, 4).cpu().detach().numpy(), inputs[0, 3+50*4:].reshape(50, 3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
